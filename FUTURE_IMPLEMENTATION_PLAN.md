# ğŸš€ Aria Super Travel Agent â€” Future Implementation Plan

> **Document Purpose:** This is a comprehensive roadmap to transform Aria from a conversational travel chatbot into a full-featured **Super Travel Agent** with real-time data capabilities.
>
> **Approach:** Hybrid strategy using **Browser Automation (Playwright)** for free data scraping + **API integrations** for reliability where scraping is fragile or rate-limited.
>
> **Current Date:** February 2026

---

## ğŸ“Š Current State Audit

### What's Actually Implemented Today

| # | README Feature | Implemented? | Where |
|---|----------------|:------------:|-------|
| 1 | ğŸ—£ï¸ Character.AI-like conversational personality | âœ… Yes | `config/SOUL.md` (persona) â†’ `src/character/handler.ts` (loads as system prompt) |
| 2 | â° Proactive messaging â€” Inactivity nudge | âœ… Yes | `src/scheduler.ts` â†’ `checkInactiveUsers()` â€” cron every 15min, DB anti-spam |
| 3 | â° Proactive messaging â€” Daily tips | âœ… Yes | `src/scheduler.ts` â†’ `sendDailyTips()` â€” cron at 9 AM, randomized tips |
| 4 | â° Proactive messaging â€” Weekly deals | âŒ **Stub only** | `src/scheduler.ts` â†’ `scrapeAndNotifyDeals()` â€” just a `console.log` + `// TODO` |
| 5 | ğŸŒ Browser automation (flights, restaurants, deals) | âš ï¸ **Code exists but broken** | `src/browser.ts` â€” has `scrapeFlightDeals()`, `checkRestaurantAvailability()`, `scrapeTravelDeals()` but uses **fake CSS selectors** (`[data-price]`, `[data-airline]`) that don't match real Google Flights/OpenTable pages. **Also never called from handler.** |
| 6 | ğŸ” Multi-layer prompt injection protection | âœ… Yes | `src/character/sanitize.ts` (input: 15+ regex patterns, Unicode tricks, suspicious word count) + `src/character/handler.ts` (sandwich defense) + `src/character/output-filter.ts` (output: forbidden patterns, voice check, length cap) |
| 7 | ğŸ‘¥ Multi-user session management | âœ… Yes | `src/character/session-store.ts` â€” PostgreSQL-backed users, sessions (JSONB), rate limiting (15/min), history trimming, usage analytics |
| 8 | ğŸ“ Google Places integration | âŒ **Not implemented** | SOUL.md mentions "local-places skill" and `.env.example` accepts `GOOGLE_PLACES_API_KEY` but **zero code** calls the Google Places API anywhere |

### Critical Gaps

1. **No tool/function calling** â€” The AI cannot trigger any browser scraping or API call from conversation. `handler.ts` does a single `groq.chat.completions.create()` with no `tools` parameter.
2. **Browser functions are disconnected** â€” `browser.ts` exports functions but nothing imports or calls them except `initBrowser()`/`closeBrowser()` in `index.ts`.
3. **Selectors are fabricated** â€” The CSS selectors in `browser.ts` are placeholder guesses that will fail on real websites.
4. **No Google Places code** â€” Claimed in README, env var exists, but no implementation.
5. **Weekly deals is a stub** â€” Just logs to console.

---

## ğŸ—ï¸ Implementation Phases

### Phase 1: Core Plumbing â€” Tool Calling + Smart Scraping (Week 1-2)

**Goal:** Make Aria able to autonomously decide WHEN to fetch real-time data and HOW to present it.

#### New Files to Create

| File | Purpose |
|------|---------|
| `src/tools.ts` | Define Groq function-calling tool schemas + tool execution router |
| `src/scrapers/google-flights.ts` | Playwright scraper for Google Flights with AI-powered text extraction |
| `src/scrapers/google-maps.ts` | Playwright scraper for Google Maps place search |
| `src/scrapers/google-hotels.ts` | Playwright scraper for Google Hotels |
| `src/scrapers/google-weather.ts` | Playwright scraper for Google Search weather widget |
| `src/scrapers/google-currency.ts` | Playwright scraper for Google Search currency converter |
| `src/scrapers/deals.ts` | Playwright scraper for SecretFlying / TheFlightDeal |
| `src/scrapers/index.ts` | Barrel export for all scrapers |
| `src/places.ts` | Google Places API integration (the missing feature) |

#### Existing Files to Modify

| File | What Changes | Why |
|------|-------------|-----|
| `src/character/handler.ts` | **Major rewrite** â€” Add `tools` parameter to Groq call, implement tool-calling loop (call Groq â†’ detect tool_calls â†’ execute scraper/API â†’ feed results back â†’ call Groq again for final response). Increase `MAX_TOKENS` from 500 to 1000. Add tool-result context to system prompt. | Currently does a single Groq call with no tool awareness. The AI literally cannot trigger any external data fetch. |
| `src/browser.ts` | **Replace entirely** â€” Remove fake selectors. New approach: generic `scrapePageText(url)` function that grabs all visible text from any page, plus per-site scraper modules in `src/scrapers/`. Let the LLM parse the raw text instead of relying on fragile CSS selectors. | Current selectors like `[data-price]`, `[data-airline]` are fabricated and will fail on every real website. |
| `src/scheduler.ts` | **Fix `scrapeAndNotifyDeals()`** â€” Import from `src/scrapers/deals.ts`, scrape real deal sites, use Groq to summarize scraped text into a friendly message, send to opted-in users. Also check `deal_alerts_enabled` column from `proactive.sql`. | Currently a `// TODO` stub that just logs to console. |
| `src/index.ts` | Add new env var validation for optional API keys. Update health check to show which scrapers/APIs are available. | Needs to handle new configuration for Places API, optional API keys, scraper health. |
| `config/SOUL.md` | Add a new section: `## Tools Available` â€” Tell Aria she can search for real flights, places, hotels, weather, currency. Instruct her to present scraped results in her casual voice, not as raw data dumps. | Currently SOUL.md mentions "local-places skill" that doesn't exist. Need to match persona with actual capabilities. |
| `package.json` | Add `playwright-extra` and `puppeteer-extra-plugin-stealth` dependencies for anti-detection. Optionally add `@googlemaps/google-maps-services-js` for Places API. | Current Playwright setup will get blocked by Google/OpenTable without stealth measures. |
| `.env.example` | Add new env vars: `AMADEUS_API_KEY` (optional), `OPENWEATHERMAP_API_KEY` (optional), `SERPAPI_KEY` (optional), `SCRAPER_COOLDOWN_MS`, `MAX_SCRAPES_PER_HOUR`. | Need configuration for new APIs and scraper rate limiting. |
| `docker-compose.yml` | Increase `shm_size` to `2gb`. Add env vars for new API keys. | More browser tabs = more shared memory needed. |
| `Dockerfile` | No changes needed â€” already uses Playwright base image with Chromium. | Already set up correctly for browser automation. |

---

### Phase 2: Real-Time Data Capabilities (Week 3-4)

**Goal:** Give Aria access to real-time travel data through browser scraping and selective APIs.

#### Capability Matrix â€” Browser Scraping vs API

| Capability | Browser Scraping ğŸŒ | API Alternative ğŸ’³ | Recommendation |
|------------|---------------------|-------------------|----------------|
| âœˆï¸ **Flight search** | Scrape Google Flights â†’ LLM extracts prices from raw text | Amadeus API (free tier: 500 calls/mo) or SerpAPI ($50/mo) | **Start with scraping**, fall back to API if Google blocks |
| ğŸ¨ **Hotel search** | Scrape Google Hotels â†’ LLM extracts prices | Booking.com Affiliate API (free, needs approval) | **Start with scraping** |
| ğŸ• **Restaurant/place finder** | Scrape Google Maps â†’ LLM extracts listings | Google Places API (free: $200 credit/mo â‰ˆ 7,000 calls) | **Use API** â€” most reliable, free tier is generous |
| ğŸŒ¤ï¸ **Weather** | Scrape Google Search weather widget | OpenWeatherMap (free: 1,000 calls/day) | **Scraping preferred** â€” dead simple, no API key needed |
| ğŸ’± **Currency conversion** | Scrape Google Search converter | ExchangeRate-API (free: 1,500 calls/mo) | **Scraping preferred** â€” one page load, always accurate |
| âœˆï¸ **Travel deals** | Scrape SecretFlying, TheFlightDeal, etc. | No good free API exists | **Scraping only** â€” this is what scraping is made for |
| ğŸ“ **Nearby attractions** | Scrape Google Maps "things to do" | Google Places API | **Use API** â€” structured data is much better here |
| ğŸšŒ **Transit/directions** | Scrape Google Maps directions | Google Directions API (free tier) | **Use API** â€” scraping directions is extremely fragile |
| ğŸ“¸ **Place photos** | Scrape Google Maps photo thumbnails | Google Places Photos API | **Use API** â€” direct image URLs, no scraping headaches |
| ğŸ›¡ï¸ **Travel advisories** | Scrape government travel advisory sites | Travel Advisory API (free) | **Either works** â€” API is cleaner |

#### Scraping Architecture (The Smart Way)

Instead of brittle CSS selectors, use this pattern:

```
User: "Find me cheap flights from Delhi to London"
  â†“
Groq detects intent â†’ calls tool: search_flights({from: "Delhi", to: "London"})
  â†“
Playwright loads Google Flights URL
  â†“
Extract ALL visible text from page (document.body.innerText)
  â†“
Truncate to ~4000 chars to fit in LLM context
  â†“
Feed raw text back to Groq as tool result
  â†“
Groq (in Aria's voice) interprets and summarizes:
"Ooh Delhi to London! ğŸ‡¬ğŸ‡§ I'm seeing some solid options â€” 
Air India has a direct flight for around â‚¹32,000, and 
there's a Turkish Airlines one-stop for â‚¹28,500. 
Want me to dig into dates?"
```

This approach is **resilient to layout changes** because the LLM parses meaning, not DOM structure.

#### Scraper Anti-Detection Strategy

Changes needed in `src/browser.ts`:

1. **Random delays** between page loads (2-5 seconds)
2. **Rotate User-Agent strings** per session
3. **Use `playwright-extra` with stealth plugin** to bypass bot detection
4. **Per-site cooldowns** â€” Max 1 scrape per site per 30 seconds
5. **Graceful degradation** â€” If scrape fails (CAPTCHA, block), Aria says "Hmm, couldn't check that right now" instead of crashing
6. **Request queuing** â€” Don't open 10 browser tabs simultaneously
7. **Daily scrape budget** â€” Track scrapes in DB, cap at configurable limit (e.g., 200/day)

#### New Database Tables

File to modify: `database/schema.sql`

```sql
-- Scraper rate limiting and tracking
CREATE TABLE IF NOT EXISTS scrape_log (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    scraper_name VARCHAR(50) NOT NULL,
    url TEXT NOT NULL,
    success BOOLEAN DEFAULT TRUE,
    response_length INTEGER,
    duration_ms INTEGER,
    error_message TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_scrape_log_name_created ON scrape_log(scraper_name, created_at DESC);

-- User preferences (extended)
ALTER TABLE users ADD COLUMN IF NOT EXISTS preferred_currency VARCHAR(10) DEFAULT 'USD';
ALTER TABLE users ADD COLUMN IF NOT EXISTS budget_level VARCHAR(20) DEFAULT 'moderate';
ALTER TABLE users ADD COLUMN IF NOT EXISTS dietary_preferences TEXT[];
ALTER TABLE users ADD COLUMN IF NOT EXISTS travel_style VARCHAR(50) DEFAULT 'balanced';
```

---

### Phase 3: Memory & Personalization (Week 5-6)

**Goal:** Make Aria remember user preferences across conversations and personalize every recommendation.

#### New Files

| File | Purpose |
|------|---------|
| `src/memory.ts` | Semantic memory system â€” extract and store user preferences from conversation ("I'm vegetarian", "I hate crowds", "I love street food") |
| `src/itinerary.ts` | Multi-day trip planner â€” structured itinerary generation with time slots, maps links, booking links |

#### Existing Files to Modify

| File | What Changes |
|------|-------------|
| `src/character/session-store.ts` | Add `getUserPreferences()` and `updatePreference()` methods. New `user_preferences` table with key-value pairs extracted by LLM. |
| `src/character/handler.ts` | After each message, ask Groq to extract any new preferences mentioned (dietary, budget, travel style). Inject known preferences into system prompt context. |
| `config/SOUL.md` | Add section: `## User Memory` â€” Instruct Aria to reference known preferences naturally ("Since you love spicy food, you'd love..."). |
| `database/schema.sql` | Add `user_preferences` table and `trip_plans` table. |

#### Memory Extraction Approach

After every conversation turn, make a lightweight secondary Groq call:

```
System: "Extract any user preferences from this message. 
Return JSON or 'none'. Categories: dietary, budget, 
travel_style, interests, dislikes, allergies."

User message: "I'm vegetarian and I prefer budget hostels"

Output: {"dietary": "vegetarian", "budget": "budget", "accommodation": "hostels"}
```

Store in DB. Inject into future system prompts:
```
## Known Preferences for John
- Diet: Vegetarian
- Budget: Budget-friendly
- Accommodation: Prefers hostels
- Location: Based in London
```

---

### Phase 4: Multi-Channel Enhancement (Week 7-8)

**Goal:** Expand beyond Telegram with richer message formats.

#### Existing Files to Modify

| File | What Changes |
|------|-------------|
| `src/channels.ts` | Add Discord adapter. Add rich message support (inline buttons for Telegram, Block Kit for Slack, embeds for Discord). Add photo/image sending capability. |
| `src/index.ts` | Add Discord webhook endpoint. Add web chat REST API endpoint (`POST /api/chat`). |
| `src/character/handler.ts` | Return structured responses with optional metadata (images, buttons, maps links) instead of plain text. Let channel adapters format appropriately. |

#### New Files

| File | Priority | Purpose |
|------|:--------:|---------|
| `src/channels/discord.ts` | ğŸŸ¢ P3 | Discord bot adapter using discord.js |
| `src/channels/web-chat.ts` | ğŸŸ¢ P3 | REST API adapter for embedding Aria in websites |
| `src/rich-messages.ts` | ğŸŸ¢ P2 | Unified rich message format â€” text + optional images, buttons, cards, maps links. Each channel adapter converts to platform-specific format. |

---

### Phase 5: Advanced Agent Capabilities (Week 9-12)

**Goal:** Transform from chatbot to autonomous travel agent.

#### New Capabilities

| Capability | Implementation | Files |
|------------|---------------|-------|
| ğŸ—ºï¸ **Itinerary builder** | Multi-day structured plans with time slots. Groq generates with structured JSON output. Include Google Maps links, estimated costs, transit between stops. | New: `src/itinerary.ts` |
| ğŸ“¸ **Photo sharing** | Scrape Google Maps place photos OR use Places Photos API. Send images in Telegram/Discord. | Modify: `src/channels.ts`, `src/browser.ts` |
| ğŸ—£ï¸ **Voice messages** | Accept Telegram voice messages â†’ Groq Whisper API for transcription â†’ process as text â†’ respond with text. | Modify: `src/channels.ts`, `src/character/handler.ts` |
| ğŸ‘¥ **Group trip planning** | Detect group chat context. Track multiple travelers' preferences. Resolve conflicts ("2 want beach, 1 wants mountains"). | New: `src/group-trips.ts`. Modify: `src/character/session-store.ts` |
| ğŸ“… **Calendar export** | Generate `.ics` files from itineraries. Google Calendar deep links. | New: `src/calendar.ts` |
| ğŸ”” **Price alerts** | User says "alert me if Delhiâ†’London drops below â‚¹25k". Scheduler checks periodically via scraping. | New: `src/alerts.ts`. Modify: `src/scheduler.ts`, `database/schema.sql` |
| ğŸ’° **Budget tracker** | Track trip spending in conversation. "I spent â‚¹500 on lunch". Running total. | New: `src/budget.ts`. Modify: `src/character/session-store.ts` |

---

## ğŸ“ Complete File Change Map

### Files That Stay Unchanged âœ…

| File | Why |
|------|-----|
| `tsconfig.json` | TypeScript config is already correct (ES2022, NodeNext) |
| `database/proactive.sql` | Proactive messaging tables are already well-designed |
| `src/character/sanitize.ts` | Input sanitization is solid â€” 15+ patterns, Unicode handling |
| `src/character/output-filter.ts` | Output filtering works well â€” forbidden patterns, voice check, length cap |
| `src/character/index.ts` | Barrel export â€” just add new exports as modules are created |
| `.gitignore` | No changes needed |

### Files That Need Modification ğŸ”§

| File | Priority | Change Scope | Summary |
|------|:--------:|:------------:|---------|
| `src/character/handler.ts` | ğŸ”´ P0 | **Major** | Add tool-calling loop with Groq. Import `ARIA_TOOLS` and `executeTool` from `src/tools.ts`. Change single Groq call to a loop: call â†’ detect `tool_calls` â†’ execute â†’ feed results back â†’ call again. Increase `MAX_TOKENS` to 1000. Add tools-awareness to system prompt. |
| `src/browser.ts` | ğŸ”´ P0 | **Major** | Replace entirely. Remove all fake selectors. New approach: `scrapePageText(url)` generic function that extracts `document.body.innerText`. Add anti-detection (stealth plugin, random delays, User-Agent rotation). Add `scrapeWithRetry()` wrapper. Add per-site cooldown tracking. Individual scraper functions move to `src/scrapers/`. |
| `src/scheduler.ts` | ğŸŸ¡ P1 | **Medium** | Fix `scrapeAndNotifyDeals()` â€” import from `src/scrapers/deals.ts`, scrape real sites, use Groq to summarize into friendly message, send to opted-in users. Optionally add price-alert checking cron job. |
| `config/SOUL.md` | ğŸŸ¡ P1 | **Medium** | Add `## Tools Available` section listing all capabilities. Add `## User Memory` section for preference-aware responses. Remove reference to non-existent "local-places skill". Add instruction to present scraped data naturally. |
| `src/index.ts` | ğŸŸ¡ P1 | **Small** | Validate new env vars on startup. Update health check to list available scrapers and API integrations. Add optional web-chat endpoint. |
| `src/channels.ts` | ğŸŸ¢ P2 | **Medium** | Add Discord adapter. Add rich message support (buttons, images). Add `sendPhoto()` method to `ChannelAdapter` interface. |
| `src/character/session-store.ts` | ğŸŸ¢ P2 | **Medium** | Add `getUserPreferences()`, `updatePreference()`, `getPreferencesForPrompt()`. New queries for user_preferences table. |
| `package.json` | ğŸŸ¡ P1 | **Small** | Add dependencies: `playwright-extra`, `puppeteer-extra-plugin-stealth`. Optionally: `@googlemaps/google-maps-services-js`, `ical-generator`, `discord.js`. |
| `.env.example` | ğŸŸ¡ P1 | **Small** | Add: `AMADEUS_API_KEY`, `OPENWEATHERMAP_API_KEY`, `SERPAPI_KEY` (all optional), `SCRAPER_COOLDOWN_MS=30000`, `MAX_SCRAPES_PER_HOUR=200`, `SCRAPER_FALLBACK_TO_API=true`. |
| `docker-compose.yml` | ğŸŸ¢ P2 | **Small** | Increase `shm_size` to `2gb`. Add new optional env vars. |
| `database/schema.sql` | ğŸŸ¢ P2 | **Small** | Add `scrape_log` table, `user_preferences` table, `price_alerts` table, `trip_plans` table. Add columns to `users` table for preferences. |
| `setup.sh` | ğŸŸ¢ P3 | **Small** | Add prompts for new optional API keys during interactive setup. |
| `deploy/digitalocean.md` | ğŸŸ¢ P3 | **Small** | Update deployment docs with new env vars and increased memory requirements. |
| `README.md` | ğŸŸ¢ P3 | **Small** | Update feature list to reflect actual vs planned. Add tool-calling capabilities. Update architecture diagram. |

### New Files to Create ğŸ†•

| File | Priority | Purpose |
|------|:--------:|---------|
| `src/tools.ts` | ğŸ”´ P0 | Groq function-calling tool schemas (search_flights, search_places, search_hotels, check_weather, convert_currency, find_deals). Tool execution router that maps tool names to scraper/API functions. |
| `src/scrapers/index.ts` | ğŸ”´ P0 | Barrel export for all scraper modules |
| `src/scrapers/base.ts` | ğŸ”´ P0 | Base scraper class with anti-detection, cooldowns, retry logic, error handling, scrape logging |
| `src/scrapers/google-flights.ts` | ğŸ”´ P0 | Google Flights scraper â€” build URL from `{from, to, date}`, load page, extract visible text, return for LLM parsing |
| `src/scrapers/google-maps.ts` | ğŸ”´ P0 | Google Maps scraper â€” search places, extract listings text |
| `src/scrapers/google-hotels.ts` | ğŸŸ¡ P1 | Google Hotels scraper â€” search by location + dates |
| `src/scrapers/google-weather.ts` | ğŸŸ¡ P1 | Google Search weather widget scraper â€” simplest scraper, just search "weather {city}" |
| `src/scrapers/google-currency.ts` | ğŸŸ¡ P1 | Google Search currency converter scraper |
| `src/scrapers/deals.ts` | ğŸŸ¡ P1 | SecretFlying + TheFlightDeal scraper for weekly deal alerts |
| `src/places.ts` | ğŸŸ¡ P1 | Google Places API integration (the missing claimed feature) â€” `searchPlaces()`, `getPlaceDetails()`, `getPlacePhotos()` |
| `src/memory.ts` | ğŸŸ¢ P2 | Semantic memory â€” extract preferences from conversation via secondary LLM call, store in DB, inject into future prompts |
| `src/itinerary.ts` | ğŸŸ¢ P2 | Multi-day trip planner with structured JSON output from Groq |
| `src/rich-messages.ts` | ğŸŸ¢ P2 | Unified rich message format (text + images + buttons + maps links) |
| `src/channels/discord.ts` | ğŸŸ¢ P3 | Discord bot adapter |
| `src/channels/web-chat.ts` | ğŸŸ¢ P3 | REST API adapter for website embedding |
| `src/alerts.ts` | ğŸŸ¢ P3 | Price alert system â€” user sets target price, scheduler checks periodically |
| `src/budget.ts` | ğŸŸ¢ P3 | Trip budget tracker |
| `src/calendar.ts` | ğŸŸ¢ P3 | iCal export from itineraries |

---

## ğŸ’° Cost Analysis

### Browser-Only Approach (No Paid APIs)

| Item | Monthly Cost |
|------|:----------:|
| DigitalOcean 4GB Droplet | $24 |
| DigitalOcean Managed PostgreSQL | $15 |
| Groq API (Llama 3.3-70B) | ~$3-8 |
| **Total** | **~$42-47/mo** |

### Hybrid Approach (Scraping + Free API Tiers)

| Item | Monthly Cost |
|------|:----------:|
| DigitalOcean 8GB Droplet (recommended for heavy scraping) | $48 |
| DigitalOcean Managed PostgreSQL | $15 |
| Groq API | ~$5-15 (more calls for tool-calling loops) |
| Google Places API | Free ($200 credit/mo) |
| OpenWeatherMap | Free |
| ExchangeRate-API | Free |
| **Total** | **~$68-78/mo** |

### When to Upgrade to Paid APIs

Switch from scraping to API **per capability** when:
- Google starts blocking your IP consistently (>20% failure rate)
- You need more than ~200 scrapes/day for a specific site
- Response time matters (APIs: ~200ms, scraping: ~3-5 seconds)
- You have paying users who expect reliability

---

### ğŸ”’ Scraping Risk Mitigation

| Risk | Mitigation |
|------|-----------|
| Google blocks your IP | Use residential proxy rotation (optional, ~$5/mo). Add exponential backoff. Fall back to API. |
| Site layout changes break extraction | LLM-based text extraction is resilient â€” parses meaning, not DOM structure. Only URL construction needs maintenance. |
| CAPTCHAs | Detect CAPTCHA pages (check for "unusual traffic" text). Fall back to API or skip gracefully. |
| Rate limiting | Per-site cooldowns (30s minimum). Daily budget cap. Request queue. |
| Legal concerns | Only scrape publicly visible data. Respect robots.txt. Don't store scraped data long-term. Use for real-time display only. |

---

## ğŸ¯ Priority Execution Order

```
Week 1:  src/tools.ts + src/scrapers/base.ts + src/scrapers/google-maps.ts
         â†’ Modify src/character/handler.ts for tool-calling loop
         â†’ Aria can now search real places from conversation!

Week 2:  src/scrapers/google-flights.ts + src/scrapers/google-weather.ts + src/scrapers/google-currency.ts
         â†’ Modify config/SOUL.md with tool awareness
         â†’ Aria can check flights, weather, currency!

Week 3:  src/places.ts (Google Places API â€” the missing feature)
         src/scrapers/deals.ts + fix src/scheduler.ts
         â†’ Real weekly deals + Places API as reliable fallback

Week 4:  src/scrapers/google-hotels.ts + src/memory.ts
         â†’ Modify src/character/session-store.ts for preferences
         â†’ Hotels + personalized recommendations

Week 5:  src/itinerary.ts + src/rich-messages.ts
         â†’ Modify src/channels.ts for rich messages
         â†’ Full trip planning with buttons and images

Week 6:  src/alerts.ts + src/budget.ts
         â†’ Modify src/scheduler.ts for price alert checks
         â†’ Price alerts + budget tracking

Week 7-8: src/channels/discord.ts + src/channels/web-chat.ts
           â†’ Multi-platform expansion
```

---

## ğŸ“ Target Architecture (After Full Implementation)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CHANNELS LAYER                        â”‚
â”‚  Telegram â”‚ WhatsApp â”‚ Slack â”‚ Discord â”‚ Web Chat API   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FASTIFY SERVER (index.ts)               â”‚
â”‚              Webhooks + Health + CORS                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CHARACTER HANDLER (handler.ts)              â”‚
â”‚  Input Sanitize â†’ Groq API (with tools) â†’ Output Filter â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€ TOOL CALLING LOOP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ 1. Groq decides to call tool                     â”‚    â”‚
â”‚  â”‚ 2. Execute scraper or API                        â”‚    â”‚
â”‚  â”‚ 3. Feed results back to Groq                     â”‚    â”‚
â”‚  â”‚ 4. Groq formats response in Aria's voice         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚              â”‚              â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SCRAPERS â”‚  â”‚  API LAYER  â”‚  â”‚     MEMORY & STATE       â”‚
â”‚(Playwright)â”‚  â”‚ (Fallback) â”‚  â”‚                          â”‚
â”‚           â”‚  â”‚             â”‚  â”‚ Sessions (PostgreSQL)    â”‚
â”‚ Flights   â”‚  â”‚ Google      â”‚  â”‚ User Preferences         â”‚
â”‚ Hotels    â”‚  â”‚  Places API â”‚  â”‚ Scrape Log               â”‚
â”‚ Maps      â”‚  â”‚ Weather API â”‚  â”‚ Price Alerts             â”‚
â”‚ Weather   â”‚  â”‚ Currency    â”‚  â”‚ Trip Plans               â”‚
â”‚ Currency  â”‚  â”‚  API        â”‚  â”‚ Usage Analytics          â”‚
â”‚ Deals     â”‚  â”‚ Amadeus     â”‚  â”‚                          â”‚
â”‚           â”‚  â”‚  (optional) â”‚  â”‚                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚    SCHEDULER        â”‚
                               â”‚ (node-cron)         â”‚
                               â”‚                     â”‚
                               â”‚ â€¢ Nudges (15min)    â”‚
                               â”‚ â€¢ Daily tips (9AM)  â”‚
                               â”‚ â€¢ Weekly deals (Sun)â”‚
                               â”‚ â€¢ Price alerts (1h) â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Definition of "Super Agent Done"

Aria is a Super Travel Agent when a user can have this conversation:

```
User: Hey! I'm planning a trip from Mumbai to Bali next month

Aria: Ooh Bali! ğŸŒ´ Amazing choice! Let me check what's available...
      âœˆï¸ Flights from Mumbai: I'm seeing IndiGo at â‚¹18,500 and 
      AirAsia at â‚¹15,200 (one stop via KL). 
      ğŸŒ¤ï¸ Weather in March: ~28Â°C, dry season starting â€” perfect timing!
      ğŸ’± Quick ref: â‚¹1 â‰ˆ 190 IDR right now.
      Want me to find hotels too, or build you a day-by-day itinerary?

User: Find me budget hotels near Seminyak beach

Aria: On it! ğŸ–ï¸ Here's what I found near Seminyak:
      1. The Haven Bali â€” â‚¹2,100/night, great pool, 4.5â˜…
      2. Seminyak Garden â€” â‚¹1,600/night, walkable to beach
      3. RedDoorz near Beach Walk â€” â‚¹900/night, basic but clean
      Since you mentioned you love street food last time, 
      Seminyak's Jl. Kayu Aya has amazing warungs nearby!

User: Alert me if Mumbai-Bali drops below â‚¹12,000

Aria: You got it! ğŸ”” I'll keep checking and ping you if I see 
      Mumbai â†’ Bali under â‚¹12,000. I check every few hours!
```

Every data point is **real** (scraped or API-fetched), **personalized** (remembers preferences), and delivered in **Aria's casual voice**.